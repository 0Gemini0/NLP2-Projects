{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "The best trained models can be downloaded from: https://my.pcloud.com/publink/show?code=XZwxbNZw8pmtXOdX1YrEoIBr0WSy4gINueX . To use them, unpack the zip file in the main directory of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from data import DataProcessing\n",
    "from ibm import IBM\n",
    "import globals\n",
    "import cPickle\n",
    "import os\n",
    "from test import test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "Processing the dataset and storing sentence pairs and empty translation probabilities dictionary to files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_processor = DataProcessing(\"training\")\n",
    "training_pairs = data_processor.generate_pairs(True)\n",
    "\n",
    "data_processor = DataProcessing(\"validation\")\n",
    "validation_pairs = data_processor.generate_pairs(True)\n",
    "\n",
    "data_processor = DataProcessing(\"test\")\n",
    "test_pairs = data_processor.generate_pairs(True)\n",
    "\n",
    "if (globals.EMPTY_DICT_TYPE == 'training'):\n",
    "    DataProcessing.init_translation_dict(training_pairs, True, globals.EMPTY_DICT_FILEPATH)\n",
    "elif (globals.EMPTY_DICT_TYPE == 'validation'):\n",
    "    DataProcessing.init_translation_dict(validation_pairs, True, globals.EMPTY_DICT_FILEPATH)\n",
    "elif (globals.EMPTY_DICT_TYPE == 'training_validation'):\n",
    "    DataProcessing.init_translation_dict(training_pairs + validation_pairs, True, globals.EMPTY_DICT_FILEPATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Retrieval\n",
    "\n",
    "Once the data is generated by the step above, it can be read in this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainPairs, valPairs, testPairs, transProbs = DataProcessing.get_data()\n",
    "valAlignments = DataProcessing.get_validation_alignments(globals.VALIDATION_DIRECTORY + '/' + globals.VALIDATION_ALIGNMENTS_FILENAME)\n",
    "\n",
    "data = []\n",
    "if (globals.EMPTY_DICT_TYPE == 'training'):\n",
    "    data = trainPairs\n",
    "elif (globals.EMPTY_DICT_TYPE == 'validation'):\n",
    "    data = valPairs\n",
    "elif (globals.EMPTY_DICT_TYPE == 'training_validation'):\n",
    "    data = trainPairs + valPairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IBM 1 Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ibm1 = IBM(transProbs, model = IBM.IBM1)\n",
    "transProbs_ibm1, aerTransProbs_out = ibm1.train_ibm(data, '', globals.THRESHOLD)\n",
    "output_dir = globals.IBM1_MODEL_OUTPUT_DIR\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "cPickle.dump(transProbs_ibm1, open(output_dir + \"transProbs\", \"wb\"))\n",
    "cPickle.dump(aerTransProbs_out, open(output_dir + \"aerTransProbs\", \"wb\"))\n",
    "\n",
    "loglike_dir = globals.IBM1_MODEL_OUTPUT_DIR + \"loglikelihood/\"\n",
    "aer_dir = output_dir + \"aer/\"\n",
    "if not os.path.exists(loglike_dir):\n",
    "    os.makedirs(loglike_dir)\n",
    "if not os.path.exists(aer_dir):\n",
    "    os.makedirs(aer_dir)\n",
    "\n",
    "test(IBM.IBM1, output_dir + \"transProbs\", \"\", \"\", loglike_dir)\n",
    "test(IBM.IBM1, output_dir + \"aerTransProbs\", \"\", \"\", aer_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IBM 1 Variational Bayes Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frenchWords = DataProcessing.get_vocabulary_size(data)\n",
    "\n",
    "for alpha in [0.0005, 0.005, 0.05]:\n",
    "    ibm1_b = IBM(transProbs, model=\"ibm1_bayesian\", alpha = alpha, fWords = frenchWords)\n",
    "    transProbsOut, unseenProbsOut, aerTransProbsOut, aerUnseenProbsOut = \\\n",
    "        ibm1_b.train_ibm(data, globals.THRESHOLD, valPairs = valPairs, valAlignments = valAlignments, aerEpochsThreshold=globals.EPOCHS)\n",
    "    output_dir = globals.IBM1B_MODEL_OUTPUT_DIR + \"/\" + str(alpha) + \"/\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    cPickle.dump(transProbsOut, open(output_dir + \"transProbs\", \"wb\"))\n",
    "    cPickle.dump(unseenProbsOut, open(output_dir + \"unseenProbs\", \"wb\"))\n",
    "    cPickle.dump(aerTransProbsOut, open(output_dir + \"aerTransProbs\", \"wb\"))\n",
    "    cPickle.dump(aerUnseenProbsOut, open(output_dir +  \"aerUnseenProbs\", \"wb\"))\n",
    "    \n",
    "    loglike_dir = output_dir + \"loglikelihood/\"\n",
    "    aer_dir = globals.IBM1B_MODEL_OUTPUT_DIR + \"aer/\"\n",
    "    if not os.path.exists(loglike_dir):\n",
    "        os.makedirs(loglike_dir)\n",
    "    if not os.path.exists(aer_dir):\n",
    "        os.makedirs(aer_dir)\n",
    "    \n",
    "    test(IBM.IBM1B, output_dir + \"transProbs\", output_dir + \"unseenProbs\", \"\", loglike_dir)\n",
    "    test(IBM.IBM1B, output_dir + \"aerTransProbs\", output_dir + \"aerUnseenProbs\", \"\", aer_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IBM 2 Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "methods = ['uniform', 'random', 'random', 'random']\n",
    "\n",
    "for init_method in methods:\n",
    "    ibm2 = IBM(transProbs, method=init_method, model=IBM.IBM2)\n",
    "    transProbsOut, vogelProbsOut, aerTransProbsOut, aerVogelProbsOut = ibm2.train_ibm(data, globals.THRESHOLD, valPairs=valPairs, valAlignments=valAlignments, aerEpochsThreshold=globals.EPOCHS)\n",
    "\n",
    "    output_dir = globals.IBM2_MODEL_OUTPUT_DIR + \"/\" + init_method + \"/\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    cPickle.dump(transProbsOut, open(output_dir + \"transProbs\", \"wb\"))\n",
    "    cPickle.dump(vogelProbsOut, open(output_dir  + \"vogelProbs\", \"wb\"))\n",
    "    cPickle.dump(aerTransProbsOut, open(output_dir  + \"aerTransProbs\", \"wb\"))\n",
    "    cPickle.dump(aerVogelProbsOut, open(output_dir + \"aerVogelProbs\", \"wb\"))\n",
    "\n",
    "    loglike_dir = output_dir + \"loglikelihood/\"\n",
    "    aer_dir = output_dir + \"aer/\"\n",
    "    if not os.path.exists(loglike_dir):\n",
    "        os.makedirs(loglike_dir)\n",
    "    if not os.path.exists(aer_dir):\n",
    "        os.makedirs(aer_dir)\n",
    "\n",
    "    test(IBM.IBM2, output_dir + \"transProbs\", \"\", output_dir + \"vogelProbs\", loglike_dir)\n",
    "    test(IBM.IBM2, output_dir + \"aerTransProbs\", \"\",  output_dir + \"aerVogelProbs\", aer_dir)\n",
    "\n",
    "ibm2 = IBM(transProbs, model=IBM.IBM2)\n",
    "ibm2.set_trans_probs(transProbs_ibm1)\n",
    "transProbsOut, vogelProbsOut, aerTransProbsOut, aerVogelProbsOut = ibm2.train_ibm(data, globals.THRESHOLD, valPairs=valPairs, valAlignments=valAlignments, aerEpochsThreshold=globals.EPOCHS)\n",
    "\n",
    "output_dir = globals.IBM2_MODEL_OUTPUT_DIR + \"/\" + \"ibm1_pretrained\" + \"/\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "cPickle.dump(transProbsOut, open(output_dir + \"transProbs\", \"wb\"))\n",
    "cPickle.dump(vogelProbsOut, open(output_dir + \"vogelProbs\", \"wb\"))\n",
    "cPickle.dump(aerTransProbsOut, open(output_dir + \"aerTransProbs\", \"wb\"))\n",
    "cPickle.dump(aerVogelProbsOut, open(output_dir + \"aerVogelProbs\", \"wb\"))\n",
    "\n",
    "loglike_dir = output_dir + \"loglikelihood/\"\n",
    "aer_dir = output_dir + \"aer/\"\n",
    "if not os.path.exists(loglike_dir):\n",
    "    os.makedirs(loglike_dir)\n",
    "if not os.path.exists(aer_dir):\n",
    "    os.makedirs(aer_dir)\n",
    "\n",
    "test(IBM.IBM2, output_dir + \"transProbs\", output_dir + \"unseenProbs\", \"\", loglike_dir)\n",
    "test(IBM.IBM2, output_dir + \"aerTransProbs\", output_dir + \"aerUnseenProbs\", \"\", aer_dir)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Python 2]",
   "language": "python",
   "name": "conda-env-Python 2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
