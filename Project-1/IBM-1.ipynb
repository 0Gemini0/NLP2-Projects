{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is IBM model 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import cPickle\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Constants\n",
    "TRAIN_DATA = \"training_pairs\"\n",
    "VAL_DATA = \"validation_pairs\"\n",
    "DICT = \"training_empty_dictionary\"\n",
    "EPOCHS = 10\n",
    "THRESHOLD = 0.001\n",
    "\n",
    "# Get data\n",
    "trainPairs = cPickle.load(open(TRAIN_DATA, 'rb'))\n",
    "valPairs = cPickle.load(open(VAL_DATA, 'rb'))\n",
    "transProbs = cPickle.load(open(DICT, 'rb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# EM-protocol\n",
    "def initialize_ibm_1(transProbs):\n",
    "    trans = {}\n",
    "    for key in transProbs:\n",
    "        trans[key] = {}\n",
    "        for secKey in transProbs[key]:\n",
    "            trans[key][secKey] = random.uniform(0.00001, 0.9999999)\n",
    "    return trans\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_ibm_1(pairs, criteria, val):\n",
    "    # trains an ibm 1 model\n",
    "    converged = False\n",
    "    logLikelihood = []\n",
    "    transProbs = initialize_ibm_1(transProbs)\n",
    "    \n",
    "    while(!converged):\n",
    "        logLike = 0\n",
    "        \n",
    "        # set all counts to zero\n",
    "        counts = {}\n",
    "        countsEnglish = {}\n",
    "        for key in transProbs:\n",
    "            counts[key] = {}\n",
    "            countsEnglish[key] = 0.0\n",
    "            for secKey in transProbs[key]:\n",
    "                counts[key][secKey] = 0.0\n",
    "        \n",
    "        # loop over sentences, french words and english words\n",
    "        # Expectation - step\n",
    "        for pair in pairs:\n",
    "            logLike += np.log(1 / (len(pair[0])+1) ** len(pair[1]))\n",
    "            for i, fWord in enumerate(pair[1]):\n",
    "                # calculate the normalizer of the posterior probability of this french word\n",
    "                normalizer = 0\n",
    "                for eWord in enumerate(pair[0]):\n",
    "                    normalizer += transProbs[eWord][fWord]\n",
    "                    \n",
    "                logLike += log(normalizer)\n",
    "                # get the expected counts based on the posterior probabilities\n",
    "                for j, eWord in enumerate(pair[0]):\n",
    "                    counts[eWord][fWord] += (transProbs[eWord][fWord] / normalizer)\n",
    "                    countsEnglish[eword] += (transProbs[eWord][fWord] / normalizer)\n",
    "                    \n",
    "        logLikelihood.append(logLike)\n",
    "        \n",
    "        # check for log-likelihood convergence\n",
    "        if len(logLikelihood) > 1:\n",
    "            difference = logLikelihood[-1] - logLikelihood[-2]\n",
    "            if difference < THRESHOLD:\n",
    "                converged = True\n",
    "                break\n",
    "                    \n",
    "        # Maximization - step\n",
    "        for eKey in transProbs:\n",
    "            for fKey in transProbs[eKey]:\n",
    "                transProbs[eKey][fKey] = counts[eKey][fKey] / countsEnglish[eKey]\n",
    "                \n",
    "                \n",
    "            \n",
    "        \n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(len(logLikelihood)), logLikelihood, 'r*')\n",
    "plt.show()\n",
    "        \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py27]",
   "language": "python",
   "name": "Python [py27]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
