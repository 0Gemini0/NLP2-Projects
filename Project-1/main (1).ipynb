{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import dok_matrix\n",
    "from Data import Dicts, Data\n",
    "import itertools\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dicts = Dicts('dicts.pkl')\n",
    "data = Data(('training/hansards.36.2.e',\n",
    "             'training/hansards.36.2.f',\n",
    "             'validation/dev.e',\n",
    "             'validation/dev.f'), dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e_len = len(dicts.e_idx2word) + 1\n",
    "f_len = len(dicts.f_idx2word)\n",
    "N = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "theta = {we: {} for we in range(e_len)}\n",
    "for i, (se, sf) in enumerate(zip(data.file['training/hansards.36.2.e'][:N], data.file['training/hansards.36.2.f'][:N])):\n",
    "    \n",
    "    # NULL word\n",
    "    se.append(len(dicts.e_idx2word))\n",
    "    \n",
    "    for i, j in list(itertools.product(se, sf)):\n",
    "        theta[i][j] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def epoch(epoch):\n",
    "    count = {we: {wf: 0 for wf in theta[we].keys()} for we in range(e_len)}\n",
    "    total = {we: 0  for we in range(e_len)}\n",
    "    for i, (se, sf) in enumerate(zip(data.file['training/hansards.36.2.e'][:N], data.file['training/hansards.36.2.f'][:N])):\n",
    "        \n",
    "        # NULL word\n",
    "        se.append(len(dicts.e_idx2word))\n",
    "        \n",
    "        # compute normalization\n",
    "        s_total = {}\n",
    "        for wf in sf:\n",
    "            s_total[wf] = 0\n",
    "            \n",
    "            for we in se:\n",
    "                s_total[wf] += theta[we][wf]\n",
    "    \n",
    "        # collect counts\n",
    "        for we in se:\n",
    "            for wf in sf:\n",
    "                v = theta[we][wf] / s_total[wf]\n",
    "                count[we][wf] += v\n",
    "                total[we] += v\n",
    "    \n",
    "        print('\\repoch: {}\\t{:.0%}'.format(epoch, (i + 1)/ N), end='')\n",
    "    \n",
    "    # estimate probabilities\n",
    "    for we in range(e_len):\n",
    "        for wf in theta[we].keys():\n",
    "            theta[we][wf] = count[we][wf] / total[we]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\t100%\ttook: 77.11 seconds\n",
      "epoch: 1\t99%"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "for i in range(epochs):\n",
    "    s = time.time()\n",
    "    epoch(i)\n",
    "    print('\\ttook: {:.2f} seconds'.format(time.time() - s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = sorted(theta[dicts.e_word2idx['near']].items(),key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999993"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([e[1] for e in d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de 0.8208696573231715\n",
      ". 0.08095938911361239\n",
      "le 0.07164508003314833\n",
      "un 0.013276723204235787\n",
      ", 0.008998306017725562\n",
      "pour 0.002638284208114501\n",
      "bient√¥t 0.0007365693941441231\n",
      "se 0.0005469806169386398\n",
      "? 0.00012684295769575178\n",
      "annonce 5.4295854224516265e-05\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(dicts.f_idx2word[d[i][0]], d[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46182291718585683"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta[dicts.e_word2idx['the']][dicts.f_word2idx['CONSTITUTION']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [py27]",
   "language": "python",
   "name": "Python [py27]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
