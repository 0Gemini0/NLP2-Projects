{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import cPickle\n",
    "from ibm1 import IBM1\n",
    "\n",
    "class IBM2:\n",
    "    def _init_(self, transProbs, method = \"uniform\", path = \"\"):\n",
    "        if method == \"uniform\":\n",
    "            # uniform parameter initialization\n",
    "            self.uniform_init(transProbs)\n",
    "        elif method == \"random\":\n",
    "            # do some random init\n",
    "            self.random_init\n",
    "        elif method == \"ibm-1\":\n",
    "            # load or train ibm-1 as init step\n",
    "            if path is not \"\":\n",
    "                self.transProbs = cPickle.load(open(path, 'rb'))\n",
    "            else:\n",
    "                self.ibm_init\n",
    "        \n",
    "        \n",
    "    def uniform_init(self, transProbs):\n",
    "        trans = {}\n",
    "        for key in transProbs:\n",
    "            trans[key] = {}\n",
    "            vocabSize = len(transProbs[key].keys())\n",
    "            for secKey in transProbs[key]:\n",
    "                trans[key][secKey] = 1.0 / vocabSize\n",
    "        self.transProbs = trans\n",
    "        \n",
    "        \n",
    "    def random_init(self, transProbs):\n",
    "        # random parameter initialization\n",
    "        \n",
    "        \n",
    "    def ibm_init(self, transProbs):\n",
    "        # ibm parameter initialization\n",
    "        model1 = IBM1(transProbs)\n",
    "        self.transProbs = model1.train_ibm_1()\n",
    "        \n",
    "\n",
    "    def train_ibm_2(self, pairs, criteria, threshold, val, transProbs = False):\n",
    "        # trains an ibm 1 model\n",
    "        converged = False\n",
    "        logLikelihood = []\n",
    "        if not transProbs:\n",
    "            transProbs = self.transProbs # initialize_ibm_1(transProbs)\n",
    "        else:\n",
    "            self.randomize(transProbs)\n",
    "            transProbs = self.transProbs\n",
    "            \n",
    "        while (not converged):\n",
    "            logLike = 0\n",
    "\n",
    "            # set all counts to zero\n",
    "            counts = {}\n",
    "            countsEnglish = {}\n",
    "            for key in transProbs:\n",
    "                counts[key] = {}\n",
    "                countsEnglish[key] = 0.0\n",
    "                for secKey in transProbs[key]:\n",
    "                    counts[key][secKey] = 0.0\n",
    "\n",
    "            # loop over sentences, french words and english words\n",
    "            # Expectation - step\n",
    "            print \"E\"\n",
    "            for pair in pairs:\n",
    "                logLike += -(len(pair[1]) * np.log(len(pair[0])+1))\n",
    "                for fWord in pair[1]:\n",
    "                    # calculate the normalizer of the posterior probability of this french word\n",
    "                    normalizer = 0\n",
    "                    for eWord in pair[0]:\n",
    "                        normalizer += transProbs[eWord][fWord]\n",
    "\n",
    "                    logLike += np.log(normalizer)\n",
    "                    # get the expected counts based on the posterior probabilities\n",
    "                    for eWord in pair[0]:\n",
    "                        counts[eWord][fWord] += (transProbs[eWord][fWord] / normalizer)\n",
    "                        countsEnglish[eWord] += (transProbs[eWord][fWord] / normalizer)\n",
    "\n",
    "            logLikelihood.append(logLike)\n",
    "            print logLike\n",
    "\n",
    "            # check for log-likelihood convergence\n",
    "            if len(logLikelihood) > 1:\n",
    "                difference = logLikelihood[-1] - logLikelihood[-2]\n",
    "                if difference < threshold:\n",
    "                    converged = True\n",
    "                    break\n",
    "\n",
    "            # Maximization - step\n",
    "            print \"M\"\n",
    "            for eKey in transProbs:\n",
    "                for fKey in transProbs[eKey]:\n",
    "                    transProbs[eKey][fKey] = counts[eKey][fKey] / countsEnglish[eKey]\n",
    "\n",
    "        return transProbs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [py27]",
   "language": "python",
   "name": "Python [py27]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
